{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7015a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc; gc.enable()\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from openbabel import pybel\n",
    "pybel.ob.obErrorLog.SetOutputLevel(0)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from ase import Atoms\n",
    "\n",
    "from nice.blocks import *\n",
    "from nice.utilities import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b34e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = Atoms(positions = np.random.rand(5, 3), numbers =  [1, 1, 1, 6, 6])\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/train.csv', index_col=0)\n",
    "test = pd.read_csv('../data/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d4554f",
   "metadata": {},
   "source": [
    "## build graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybel_molecule import build_molecules_pybel\n",
    "\n",
    "data_molecules = build_molecules_pybel(data['Smiles'].values)\n",
    "data_targets = data['Active'].values.astype(np.int64)\n",
    "for index in range(len(data_molecules)):\n",
    "    data_molecules[index].y = int(data['Active'].values[index])\n",
    "\n",
    "test_molecules = build_molecules_pybel(test['Smiles'].values, fixed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_distance(atoms):\n",
    "    def get_distance(first, second):\n",
    "        delta = first - second\n",
    "        return np.sum(np.sqrt(delta * delta))\n",
    "    positions = atoms.positions\n",
    "    min_d = None\n",
    "    for i in range(len(positions)):\n",
    "        for j in range(i + 1, len(positions)):\n",
    "            now = get_distance(positions[i], positions[j])\n",
    "            if (min_d is None) or (now < min_d):\n",
    "                min_d = now\n",
    "    return min_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b65aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ase = [molecule.get_ase() for molecule in tqdm(data_molecules)]\n",
    "test_ase = [molecule.get_ase() for molecule in tqdm(test_molecules)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_distance = [get_min_distance(molecule) for molecule in tqdm(data_ase)]\n",
    "test_distance =  [get_min_distance(molecule) for molecule in tqdm(test_ase)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(data_distance))\n",
    "data_bad_mask =  np.array(data_distance) < 0.5\n",
    "data_good_mask = np.logical_not(data_bad_mask)\n",
    "print(np.sum(data_bad_mask))\n",
    "print(np.sum(data_good_mask))\n",
    "\n",
    "print(np.min(test_distance))\n",
    "test_bad_mask = np.array(test_distance) < 0.5\n",
    "test_good_mask = np.logical_not(test_bad_mask)\n",
    "\n",
    "print(np.sum(test_bad_mask))\n",
    "print(np.sum(test_good_mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48afa9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ase = [data_ase[i] for i in range(len(data_good_mask)) if data_good_mask[i]]\n",
    "data_molecules = [data_molecules[i]  for i in range(len(data_good_mask)) if data_good_mask[i]]\n",
    "data = data[data_good_mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_graphs = [molecule.get_graph() for molecule in tqdm(data_molecules)]\n",
    "test_graphs = [molecule.get_graph() for molecule in tqdm(test_molecules)]\n",
    "for index in range(len(data_graphs)):\n",
    "    data_graphs[index].y = int(data['Active'].values[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39870560",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_graphs))\n",
    "print(len(data_molecules))\n",
    "print(data['Active'].values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e021e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERS = {\n",
    "    'interaction_cutoff': 4.3,\n",
    "    'max_radial': 5,\n",
    "    'max_angular': 5,\n",
    "    'gaussian_sigma_type': 'Constant',\n",
    "    'gaussian_sigma_constant': 0.2,\n",
    "    'cutoff_smooth_width': 0.3,\n",
    "    'radial_basis': 'GTO'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7812242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nice():\n",
    "    return StandardSequence([\n",
    "        StandardBlock(ThresholdExpansioner(num_expand=150),\n",
    "                      None,\n",
    "                      IndividualLambdaPCAsBoth(n_components=50),\n",
    "                      ThresholdExpansioner(num_expand=300, mode='invariants'),\n",
    "                     None,\n",
    "                      InvariantsPCA(n_components=20)),\n",
    "        StandardBlock(ThresholdExpansioner(num_expand=150),\n",
    "                      None,\n",
    "                      IndividualLambdaPCAsBoth(n_components=50),\n",
    "                      ThresholdExpansioner(num_expand=300, mode='invariants'),\n",
    "                      None,\n",
    "                      InvariantsPCA(n_components=20)),\n",
    "        StandardBlock(None, None, None,\n",
    "                      ThresholdExpansioner(num_expand=300, mode='invariants'),\n",
    "                      None,\n",
    "                      InvariantsPCA(n_components=20))\n",
    "    ],\n",
    "                            initial_scaler=InitialScaler(\n",
    "                                mode='signal integral', individually=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_species = get_all_species(data_ase + test_ase)\n",
    "print(all_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_coefficients = get_spherical_expansion(data_ase, HYPERS,\n",
    "                                             all_species, split_by_central_specie = False)\n",
    "\n",
    "test_coefficients = get_spherical_expansion(test_ase, HYPERS,\n",
    "                                            all_species, split_by_central_specie = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ff357",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coefficients = np.concatenate([data_coefficients, test_coefficients], axis = 0)\n",
    "print(all_coefficients.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(all_coefficients.shape[0])\n",
    "indices = indices[0:10000]\n",
    "nice = get_nice()\n",
    "nice.fit(all_coefficients[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ca814",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import time\n",
    "begin = time.time()\n",
    "data_features = nice.transform(data_coefficients, return_only_invariants = True)\n",
    "test_features = nice.transform(test_coefficients, return_only_invariants = True)\n",
    "print(time.time() - begin)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1000df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "data_features_raw = [nice.transform(data_coefficients[i : i + batch_size], return_only_invariants = True) \n",
    "                 for i in tqdm(range(0, data_coefficients.shape[0], batch_size))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaf7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = {}\n",
    "for key in data_features_raw[0].keys():\n",
    "    now = [el[key] for el in data_features_raw]\n",
    "    data_features[key] = np.concatenate(now, axis = 0)\n",
    "for key in data_features.keys():\n",
    "    print(key, data_features[key].shape)\n",
    "print(data_coefficients.shape)\n",
    "\n",
    "for el in data_features:\n",
    "    print(el, data_features[el].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a146bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4863bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.isnan(np.max(test_coefficients[0])))\n",
    "print(np.isnan(np.max(test_coefficients)))\n",
    "for i in range(len(test_coefficients)):\n",
    "    if np.isnan(np.max(test_coefficients[i])):\n",
    "        test_coefficients[i] = 0.0\n",
    "        \n",
    "print(np.isnan(np.max(test_coefficients[0])))\n",
    "print(np.isnan(np.max(test_coefficients)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbfc9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_coefficients)):\n",
    "    if np.sum(test_coefficients[i] ** 2) < 1e-10:\n",
    "        test_coefficients[i, 0, 0, 0] = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dc893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(test_coefficients[0]))\n",
    "print(np.max(test_coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442dc637",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3], [3,4,5]])\n",
    "a[1] = 0\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66012a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "test_features_raw = [nice.transform(test_coefficients[i : i + batch_size], return_only_invariants = True) \n",
    "                 for i in tqdm(range(0, test_coefficients.shape[0], batch_size))]\n",
    "\n",
    "test_features = {}\n",
    "for key in test_features_raw[0].keys():\n",
    "    now = [el[key] for el in test_features_raw]\n",
    "    test_features[key] = np.concatenate(now, axis = 0)\n",
    "for key in test_features.keys():\n",
    "    print(key, test_features[key].shape)\n",
    "print(test_coefficients.shape)\n",
    "\n",
    "for el in test_features:\n",
    "    print(el, test_features[el].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c16576",
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in data_graphs:\n",
    "    graph.initial_features = torch.FloatTensor(graph.x)\n",
    "    \n",
    "now = 0\n",
    "for index in range(len(data_graphs)):\n",
    "    features_now = torch.FloatTensor(data_features[2][now : now + data_graphs[index].x.shape[0]])\n",
    "    #print(features_now.shape)\n",
    "    data_graphs[index].x = torch.cat([data_graphs[index].initial_features, features_now], dim = 1)\n",
    "    now += data_graphs[index].x.shape[0]\n",
    "print(data_graphs[0].x.shape)\n",
    "print(data_features[2].shape, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ef757",
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in test_graphs:\n",
    "    graph.initial_features = torch.FloatTensor(graph.x)\n",
    "    \n",
    "now = 0\n",
    "for index in range(len(test_graphs)):\n",
    "    features_now = torch.FloatTensor(test_features[2][now : now + test_graphs[index].x.shape[0]])\n",
    "    #print(features_now.shape)\n",
    "    test_graphs[index].x = torch.cat([test_graphs[index].initial_features, features_now], dim = 1)\n",
    "    now += test_graphs[index].x.shape[0]\n",
    "print(test_graphs[0].x.shape)\n",
    "print(test_features[2].shape, now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd1a0d",
   "metadata": {},
   "source": [
    "## engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fdaa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd227a1b",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbd5a5a",
   "metadata": {},
   "source": [
    "## args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split args\n",
    "n_splits, random_state = 8, 42\n",
    "\n",
    "# positive objects rebalance args\n",
    "num_pos_repeats, pos_weight = 1, 12.0\n",
    "\n",
    "# model args\n",
    "num_features, width, depth = 60, 128, 2\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "# fit args\n",
    "batch_size, num_workers = 128, 8\n",
    "lr, num_epochs = 5e-4, 64\n",
    "\n",
    "# name for logs and checkpoints\n",
    "name = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31ed56",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30dc2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thrs, f1s, f1s_histories = [], [], []\n",
    "for index in range(n_splits):\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    tmp = cv.split(data['Smiles'].values, data['Active'].values.astype(np.int64))\n",
    "\n",
    "    for _ in range(index + 1):\n",
    "        train_indices, val_indices = tmp.__next__()\n",
    "\n",
    "    train_graphs = [data_graphs[index] for index in train_indices if not data_graphs[index].empty]\n",
    "    val_graphs = [data_graphs[index] for index in val_indices if not data_graphs[index].empty]\n",
    "\n",
    "    positive_train_graphs = [graph for graph in train_graphs if graph.y]\n",
    "    if num_pos_repeats > 1:\n",
    "        train_graphs = train_graphs + positive_train_graphs * (num_pos_repeats - 1)\n",
    "\n",
    "    train_loader = DataLoader(train_graphs, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_graphs, shuffle=False, batch_size=batch_size, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_graphs, shuffle=False, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    model = GCN(num_features, width=width, depth=depth)  # <- GCN defined in models.py, feel free to add more\n",
    "    model.to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    exp_name = name + '_' + str(index) + '_cv_split'\n",
    "    \n",
    "    # trainer defined in utils.py\n",
    "    trainer = Trainer(model, opt, None, train_loader, val_loader, num_epochs,\n",
    "                      weight=pos_weight, step='step', backup_by='all',\n",
    "                      logs_path='./logs', path_to_save='./ckpt', exp_name=exp_name, verbose=0)\n",
    "    trainer.run()\n",
    "\n",
    "    thrs.append(trainer.thr)\n",
    "    f1s.append(trainer.adaptive_f1s[trainer.best_epoch - 1])\n",
    "    f1s_histories.append(trainer.adaptive_f1s)\n",
    "    print(trainer.adaptive_f1s)\n",
    "# raise Exception('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d89344",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s_histories = np.array(f1s_histories)\n",
    "print(f1s_histories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529814a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(f1s_histories[:, 48:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc7ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    print(np.argmax(f1s_histories[i, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f283db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(num_features, width=width, depth=depth)\n",
    "model.to(device)\n",
    "test_loader = DataLoader(test_graphs, shuffle=False, batch_size=batch_size, num_workers=num_workers)\n",
    "    \n",
    "outputs_list = []\n",
    "\n",
    "selection_dict = {(42, 0): (0, 63),\n",
    "                  (42, 1): (0, 36),\n",
    "                  (42, 2): (0, 42),\n",
    "                  (42, 3): (0, 39),\n",
    "                  (42, 4): (0, 53),\n",
    "                  (42, 5): (0, 23),\n",
    "                  (42, 6): (0, 32),\n",
    "                  (42, 7): (0, 31)}\n",
    "\n",
    "outputs_list = []\n",
    "for index in tqdm(range(n_splits)):\n",
    "    jndex, epoch = selection_dict[(random_state, index)]\n",
    "    exp_name = name + '_' + str(index) + '_cv_split' + '_' + str(epoch) + '.pth'\n",
    "    model.load_state_dict(torch.load(os.path.join('./ckpt', exp_name)))\n",
    "    \n",
    "    # inference defined in utils.py\n",
    "    outputs = inference(model, test_loader)\n",
    "    outputs_list.append(outputs)\n",
    "    \n",
    "outputs_list = np.asarray(outputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs_list_second_run.pickle\", 'wb') as f:\n",
    "    pickle.dump(outputs_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = outputs_list.copy()\n",
    "tmp = np.vstack([tmp, np.mean(outputs_list, axis=0)[None]])\n",
    "tmp = 1.0 / (1.0 + np.exp(-tmp))\n",
    "for index in range(len(tmp)):\n",
    "    indices = np.argsort(tmp[index])[::-1][:57]\n",
    "    tmp[index] *= 0.0\n",
    "    tmp[index, indices] = 1.0\n",
    "\n",
    "corrs = np.zeros((len(tmp), len(tmp)), dtype=np.float)\n",
    "for index in range(len(tmp)):\n",
    "    for jndex in range(index, len(tmp)):\n",
    "        corrs[index, jndex] = corrs[jndex, index] = np.mean(tmp[index] == tmp[jndex])\n",
    "        \n",
    "plt.figure(figsize=(10, 10))\n",
    "labels = ['split ' + str(index) for index in range(n_splits)] + ['ensemble']\n",
    "sns.heatmap(corrs, xticklabels=labels, yticklabels=labels, square=True, annot=True, fmt='.3f')\n",
    "plt.title('logits cosine similarity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e796b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = 1.0 / (1.0 + np.exp(-np.mean(outputs_list, axis=0)))\n",
    "test['Active'] = False\n",
    "pos_labels = np.argsort(probs)[::-1][0:59]\n",
    "test['Active'][pos_labels] = True\n",
    "\n",
    "test['Active'].to_csv('submission_nice_new.csv')\n",
    "test['Active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca1c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sort(probs)[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ccc380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83864f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
